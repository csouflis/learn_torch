{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divine-spell",
   "metadata": {},
   "source": [
    "### Learning Pytorch\n",
    "### Pytorch led by Facebook AI Research (FAIR) is a minimal library built off Torch as a python extension of Lua which can directly use CUDA GPUs for accelerated processing - and has good codeflow.\n",
    "\n",
    "\n",
    "### The main modules of pytorch as as below and they are self explanatory in sense. \n",
    "\n",
    "<img src = \"images/pytorch_modules.png\">\n",
    "\n",
    "<br><br>\n",
    "- torch.nn = Base class for all neural network modules.\n",
    "    - torch.nn.functional = functionality to blocks of network\n",
    "<br><br>\n",
    "- torch.Tensor = multi-dimensional matrix containing elements of a single data type.\n",
    "<br><br>\n",
    "- torch.autograd = provides classes and functions implementing automatic differentiation. A recorder records what operations have performed, and then it replays it backward to compute the gradients. This method is especially powerful when building neural networks to save time on one epoch by calculating differentiation of the parameters at the forward pass. \n",
    "<br><br>\n",
    "- torch.utils.data = the heart of PyTorch data loading utility is the torch.utils.data.DataLoader class. It represents a Python iterable over a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-thermal",
   "metadata": {},
   "source": [
    "#### Make sure you have an virutal env set up with anaconda, and conda installed pytorch, cudatoolkit, and jupyter.\n",
    "\n",
    "### Verify the install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "million-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should succeed without hesitation\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "resident-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "intense-mission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify you have CUDA-supported NVIDIA GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "collect-endorsement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.2'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should match the version of cudatoolkit installed\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-minneapolis",
   "metadata": {},
   "source": [
    "### Sidenote: Why GPUs\n",
    "For tasks such as mathematical computation, it is possbile to achieve solution through parallel computing because even complex equations can be broken down into smaller computations that are independent with respect to one another. GPUs are much more capable of parallel computation because of their massive core counts.\n",
    "\n",
    "CUDA is a API library that has to be downloaded (like cudatoolkit) to enable this feature on NVIDIA GPUs.\n",
    "\n",
    "Pytorch is verstile in that it can selectively hold mathematical objects such as tensors on different devices such as the GPU or CPU. \n",
    "#### Why not use a GPU for everything?\n",
    "Moving simple computation into GPU will slow down code even more because the time it would take a modern CPU to complete the code can be done by the time the GPU receives the task. Remember GPUs are only amazing densely mathematical tasks that can be done in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "hazardous-reception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simply creating Pytorch tensor object\n",
    "t = torch.Tensor([1,2,3])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "seven-observer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing GPU\n",
    "device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "covered-indication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving tensor object to GPU\n",
    "t = t.cuda()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "turkish-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cuda:0\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(t.dtype)\n",
    "print(t.device)\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-gabriel",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "Tensors, in short, is a general term to describe a representation of numbers which can have rank, axes, and shapes. Think about an matrix, but with more dimensionability. \n",
    "\n",
    "Number of dimensions present within a tensor. How many indices you need to access an element - for example the above tensor 't' has a rank of 1 because each element only needs one index for access like t[1]. Axes are measures of which elements can exist, and multiple axes create more dimensions for elements to exist. \n",
    "\n",
    "Shapes of tensors encode all relevant info about rank, axes and even indices. Tensors are constantly reshaped and transformed (which is why their named tensors). Tensors can represent the same underlying data but have different shapes. Think about it: if 'a' was a list of lengths of toothpicks (or something weird like that) in the code below, changing its shape wouldn't change those lengths of the the toothpicks.\n",
    "\n",
    "\n",
    "Shapes can be more than 2 or 3 dimensions. For example, an image can typically have three dimensions represented by height, width, and RGB value of a pixel: [C,H,W]. However, in deep learning, more dimensions can be added, such as batch size (an amount of images in a subgroup). Now an image will have 4 dimensions and look like: [B,C,H,W]. So now as a rank 4 tensor we can navigate to a specific pixel in a specific image with a specific color. \n",
    "\n",
    "Features can be extracted from these values by transforming them with specific operations. See more later on this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "agricultural-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "typical-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "external-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "changed-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.int64 tensor([[4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "<class 'torch.Tensor'> torch.float32 tensor([[4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "#list to tensors; different tensor calls create different tensor types but still same shape\n",
    "b = torch.tensor(a)\n",
    "c = torch.Tensor(a)\n",
    "print(type(b), b.dtype, b)\n",
    "print(type(c), c.dtype,  c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "suitable-pipeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "major-spectrum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping a tensor\n",
    "b.reshape(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "square-affiliate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(1,6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "earlier-surfing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remember that calling reshape doesn't actually change b as a variable, only for runtime not storage\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "monthly-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "catholic-engineering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([1,2,3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-surge",
   "metadata": {},
   "source": [
    "#### Different ways to initiate a tensor and exploring their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "searching-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "#notice this is a different construction of a tensor then the next 4: Pytorch Class Constructor of a tensor  - unchanged by numpy array manipulation\n",
    "\n",
    "t1 = torch.Tensor(data)\n",
    "print(t1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "paperback-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "#factory function (accepts parameter inputs and outputs tensor objects) - unchanged by numpy array manipulation\n",
    "\n",
    "t2 = torch.tensor(data)\n",
    "print(t2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adjusted-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "#also a factory function --> changing the numpy array (variable 'data') will change these values\n",
    "\n",
    "t3 = torch.as_tensor(data)\n",
    "print(t3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "adult-mitchell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "#also a factory function --> changing the numpy array (variable 'data') will change these values\n",
    "\n",
    "t4 = torch.from_numpy(data)\n",
    "print(t4.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-rebound",
   "metadata": {},
   "source": [
    "### Recap\n",
    "torch.Tensor(data) & torch.tensor(data) = **data is copied** but also different data types\n",
    "<br>\n",
    "torch.as_tensor(data) & torch.from_numpy(data) = **data is shared**(saves memory space) and same data types\n",
    "<br><br>\n",
    "torch.tensor() = best for everyday use\n",
    "<br>\n",
    "torch.as_tensor() = best for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "painted-information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# data type also is inferred by incoming data\n",
    "print(torch.get_default_dtype()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "crazy-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type inference - what you put in is what it becomes\n",
    "a = torch.tensor(np.array([1,2,3]))\n",
    "print(a)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "terminal-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(np.array([1.,2.,3.]))\n",
    "print(a)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "proprietary-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explicitly set\n",
    "a = torch.tensor(np.array([1,2,3]), dtype=torch.float64)\n",
    "print(a)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-jurisdiction",
   "metadata": {},
   "source": [
    "#### Creating multi-dimensional tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "removed-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "civilian-provider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(3,2))\n",
    "print(torch.zeros(3,2).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "received-remains",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(2,3))\n",
    "print(torch.ones(2,3).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dangerous-penalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2401, 0.2106],\n",
       "        [0.1259, 0.6181]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#between 0-1 and four decimals out\n",
    "torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-stadium",
   "metadata": {},
   "source": [
    "# Main Tensor operation types:\n",
    "\n",
    "   **1. Reshaping operations**\n",
    "   <br><br>2. Element-wise operations\n",
    "   <br>3. Reduction operations\n",
    "   <br>4. Access operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-generic",
   "metadata": {},
   "source": [
    "##    1. Reshaping operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "purple-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank 2 tensor with two axes; one axis with length of 4 and made up of arrays,\n",
    "#   the other axis has length of 3 and is made up of numbers\n",
    "t = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "portuguese-queen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "polar-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "acting-shield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of shape gives rank of a tensor\n",
    "len(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-cassette",
   "metadata": {},
   "source": [
    "Find the number of elements in tensor product of dimensions or numel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "empty-disease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(t.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "polar-champion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-possible",
   "metadata": {},
   "source": [
    "All reshaping operations for this 3 by 4 tensor will always have a product of 12 b/c the elements (and # of elements) is unchanged\n",
    "\n",
    "Sidenote: that's kinda why their called tensors. Tensor elements are unchanged when ungoing transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "vietnamese-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "sporting-speech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2.],\n",
       "        [2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "proper-comfort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [2., 2.],\n",
       "        [2., 2.],\n",
       "        [3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(6,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "anonymous-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "abroad-rendering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 3.],\n",
       "         [3., 3., 3.]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can change the rank!\n",
    "t.reshape(2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-given",
   "metadata": {},
   "source": [
    "**Squeezing** allows to one to change the rank of tensor without even changing the shape (doesn't change rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "thick-forestry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12))\n",
    "print(t.reshape(1,12).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "strong-progress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12).squeeze())\n",
    "print(t.reshape(1,12).squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "universal-thomas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0))\n",
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-inspector",
   "metadata": {},
   "source": [
    "**Flattening** removes all axes except one, making it a rank 1 tensor (change rank to 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "oriented-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    t = t.reshape(1,-1)\n",
    "    t = t.squeeze()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "hybrid-greene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape and flatten (removes a set of brackets!)!\n",
    "flatten(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "rental-listing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape only\n",
    "t.reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "straight-strand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same thing as above\n",
    "t.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-symphony",
   "metadata": {},
   "source": [
    "**Concatenating** tensors (doesn't change rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ordered-bradford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "t2 = torch.tensor([\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "])\n",
    "\n",
    "#original shape\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "committed-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine t1 and t2 row-wise (axis-0)\n",
    "torch.cat((t1, t2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "armed-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine them column-wise (axis-1) \n",
    "torch.cat((t1, t2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "trained-whale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#axis 0 because listed first --> adding on axis 0 adds 2 to first number\n",
    "torch.cat((t1, t2), dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "mature-poland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#likewise for axis 1\n",
    "torch.cat((t1, t2), dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-trauma",
   "metadata": {},
   "source": [
    "### CNN Flatten Operations - Tensor Batch Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "steady-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three rank 2 tensors with shape (4,4)\n",
    "t1 = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1],\n",
    "    [1,1,1,1]\n",
    "])\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2],\n",
    "    [2,2,2,2]\n",
    "])\n",
    "\n",
    "t3 = torch.tensor([\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3],\n",
    "    [3,3,3,3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "enormous-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack is a concat function\n",
    "t = torch.stack((t1,t2,t3))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "seven-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]],\n",
       "\n",
       "        [[2, 2, 2, 2],\n",
       "         [2, 2, 2, 2],\n",
       "         [2, 2, 2, 2],\n",
       "         [2, 2, 2, 2]],\n",
       "\n",
       "        [[3, 3, 3, 3],\n",
       "         [3, 3, 3, 3],\n",
       "         [3, 3, 3, 3],\n",
       "         [3, 3, 3, 3]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rank 3 tensor\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "committed-antenna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1],\n",
       "          [1, 1, 1, 1]]],\n",
       "\n",
       "\n",
       "        [[[2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2],\n",
       "          [2, 2, 2, 2]]],\n",
       "\n",
       "\n",
       "        [[[3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3],\n",
       "          [3, 3, 3, 3]]]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we've seen we change increase the rank of a tensor with the reshape operation\n",
    "t = t.reshape(3,1,4,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-flavor",
   "metadata": {},
   "source": [
    "That tensor has lots of information stored. For example if each original tensor (t1, t2, t3) were 4 by 4 pixel grayscale images, then this final tensor *t* would have information on (batch, channel, height, width)\n",
    "\n",
    "Notice how the additional axis of length 1 as a channel doesn't change the number of elements in the tensor. This is because the product of the components values doesn't change when we multiply by one. \n",
    "\n",
    "#### The first axis has 3 elements. Each element of the first axis represents an image (an image in a batch). For each image, we have a single color channel on the channel axis (b/c it's grayscale). Each of these channels contain 4 arrays that contain 4 numbers or scalar components.\n",
    "\n",
    "Observe this by indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "funny-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1],\n",
       "         [1, 1, 1, 1]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first image\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "competitive-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first color channel in first image\n",
    "t[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "representative-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first row of the first color channel of the first image\n",
    "t[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "romance-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first pixel value in the first row of the first color channel of the first image\n",
    "t[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "welsh-rings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flattens entire batch\n",
    "t.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "prescribed-homework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leave batch tensor intact to maintain images seperate\n",
    "t.flatten(start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "worth-system",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten by the batch index (1)\n",
    "t.flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-school",
   "metadata": {},
   "source": [
    "   1. Reshaping operations\n",
    "   **2. Element-wise operations**\n",
    "   <br><br>3. Reduction operations\n",
    "   <br>4. Access operations\n",
    "\n",
    "## Element-wise Tensor Operation\n",
    "\n",
    "An element-wise operation operates on corresponding elements between tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "inappropriate-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "t2 = torch.tensor([\n",
    "    [9,8],\n",
    "    [7,6]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "homeless-spirituality",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-133-a6da4f3f8867>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-133-a6da4f3f8867>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    > print(t1[0])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Example of the first axis\n",
    "print(t1[0])\n",
    "\n",
    "# Example of the second axis\n",
    "print(t1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-proposal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
