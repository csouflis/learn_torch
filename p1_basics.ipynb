{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "divine-spell",
   "metadata": {},
   "source": [
    "### Learning Pytorch\n",
    "### Pytorch led by Facebook AI Research (FAIR) is a minimal library built off Torch as a python extension of Lua which can directly use CUDA GPUs for accelerated processing - and has good codeflow.\n",
    "\n",
    "\n",
    "### The main modules of pytorch as as below and they are self explanatory in sense. \n",
    "\n",
    "<img src = \"images/pytorch_modules.png\">\n",
    "\n",
    "<br><br>\n",
    "- torch.nn = Base class for all neural network modules.\n",
    "    - torch.nn.functional = functionality to blocks of network\n",
    "<br><br>\n",
    "- torch.Tensor = multi-dimensional matrix containing elements of a single data type.\n",
    "<br><br>\n",
    "- torch.autograd = provides classes and functions implementing automatic differentiation. A recorder records what operations have performed, and then it replays it backward to compute the gradients. This method is especially powerful when building neural networks to save time on one epoch by calculating differentiation of the parameters at the forward pass. \n",
    "<br><br>\n",
    "- torch.utils.data = the heart of PyTorch data loading utility is the torch.utils.data.DataLoader class. It represents a Python iterable over a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-thermal",
   "metadata": {},
   "source": [
    "#### Make sure you have an virutal env set up with anaconda, and conda installed pytorch, cudatoolkit, and jupyter.\n",
    "\n",
    "### Verify the install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "million-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should succeed without hesitation\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "resident-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "intense-mission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify you have CUDA-supported NVIDIA GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "collect-endorsement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.2'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should match the version of cudatoolkit installed\n",
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-minneapolis",
   "metadata": {},
   "source": [
    "### Sidenote: Why GPUs\n",
    "For tasks such as mathematical computation, it is possbile to achieve solution through parallel computing because even complex equations can be broken down into smaller computations that are independent with respect to one another. GPUs are much more capable of parallel computation because of their massive core counts.\n",
    "\n",
    "CUDA is a API library that has to be downloaded (like cudatoolkit) to enable this feature on NVIDIA GPUs.\n",
    "\n",
    "Pytorch is verstile in that it can selectively hold mathematical objects such as tensors on different devices such as the GPU or CPU. \n",
    "#### Why not use a GPU for everything?\n",
    "Moving simple computation into GPU will slow down code even more because the time it would take a modern CPU to complete the code can be done by the time the GPU receives the task. Remember GPUs are only amazing densely mathematical tasks that can be done in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "hazardous-reception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simply creating Pytorch tensor object\n",
    "t = torch.Tensor([1,2,3])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "seven-observer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing GPU\n",
    "device = torch.device('cuda:0')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "covered-indication",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-3328dec443a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Moving tensor object to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "# Moving tensor object to GPU\n",
    "t = t.cuda()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "turkish-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "print(t.dtype)\n",
    "print(t.device)\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-gabriel",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "Tensors, in short, is a general term to describe a representation of numbers which can have rank, axes, and shapes. Think about an matrix, but with more dimensionability. \n",
    "\n",
    "Number of dimensions present within a tensor. How many indices you need to access an element - for example the above tensor 't' has a rank of 1 because each element only needs one index for access like t[1]. Axes are measures of which elements can exist, and multiple axes create more dimensions for elements to exist. \n",
    "\n",
    "Shapes of tensors encode all relevant info about rank, axes and even indices. Tensors are constantly reshaped and transformed (which is why their named tensors). Tensors can represent the same underlying data but have different shapes. Think about it: if 'a' was a list of lengths of toothpicks (or something weird like that) in the code below, changing its shape wouldn't change those lengths of the the toothpicks.\n",
    "\n",
    "\n",
    "Shapes can be more than 2 or 3 dimensions. For example, an image can typically have three dimensions represented by height, width, and RGB value of a pixel: [C,H,W]. However, in deep learning, more dimensions can be added, such as batch size (an amount of images in a subgroup). Now an image will have 4 dimensions and look like: [B,C,H,W]. So now as a rank 4 tensor we can navigate to a specific pixel in a specific image with a specific color. \n",
    "\n",
    "Features can be extracted from these values by transforming them with specific operations. See more later on this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "agricultural-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "typical-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "external-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "changed-childhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.Tensor(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "suitable-pipeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "major-spectrum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "square-affiliate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(1,6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "monthly-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "catholic-engineering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([1,2,3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-surge",
   "metadata": {},
   "source": [
    "#### Different ways to initiate a tensor and exploring their data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "searching-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "#notice this is a different construction of a tensor then the next 4: Pytorch Class Constructor of a tensor  - unchanged by numpy array manipulation\n",
    "\n",
    "t1 = torch.Tensor(data)\n",
    "print(t1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "paperback-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "#factory function (accepts parameter inputs and outputs tensor objects) - unchanged by numpy array manipulation\n",
    "\n",
    "t2 = torch.tensor(data)\n",
    "print(t2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "adjusted-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "#also a factory function --> changing the numpy array (variable 'data') will change these values\n",
    "\n",
    "t3 = torch.as_tensor(data)\n",
    "print(t3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adult-mitchell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "#also a factory function --> changing the numpy array (variable 'data') will change these values\n",
    "\n",
    "t4 = torch.from_numpy(data)\n",
    "print(t4.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-rebound",
   "metadata": {},
   "source": [
    "### Recap\n",
    "torch.Tensor(data) & torch.tensor(data) = **data is copied** but also different data types\n",
    "<br>\n",
    "torch.as_tensor(data) & torch.from_numpy(data) = **data is shared**(saves memory space) and same data types\n",
    "<br><br>\n",
    "torch.tensor() = best for everyday use\n",
    "<br>\n",
    "torch.as_tensor() = best for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "painted-information",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# data type also is inferred by incoming data\n",
    "print(torch.get_default_dtype()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "crazy-remark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(np.array([1,2,3]))\n",
    "print(a)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "terminal-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(np.array([1.,2.,3.]))\n",
    "print(a)\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-jurisdiction",
   "metadata": {},
   "source": [
    "#### Creating multi-dimensional tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "removed-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "civilian-provider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "received-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dangerous-penalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2592, 0.8560],\n",
       "        [0.4719, 0.9232]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#between 0-1 and four decimals out\n",
    "torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-stadium",
   "metadata": {},
   "source": [
    "## Tensor operation types:\n",
    "\n",
    "    1. Reshaping operations\n",
    "    2. Element-wise operations\n",
    "    3. Reduction operations\n",
    "    4. Access operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-qualification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
